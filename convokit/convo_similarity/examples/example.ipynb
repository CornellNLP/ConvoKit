{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for using SCD Transformer and Compute with ConDynS\n",
    "\n",
    "We demonstrate here how to use SCD Transformer for writing SCDs with your custom prompts. Then, we show how to compute ConDynS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 03:47:14.871250: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-02 03:47:14.950271: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-02 03:47:16.470796: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from convokit import Corpus, download\n",
    "from convokit.convo_similarity import SCD\n",
    "from convokit.convo_similarity.condyns import ConDynS\n",
    "from convokit.genai import GenAIConfigManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /reef/kz88/convokit/download_corpus/friends-corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"friends-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write SCD and SoP with SCD Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config your GenAI API keys\n",
    "config = GenAIConfigManager()\n",
    "\n",
    "# Set up Google Cloud configuration for Gemini (with Vertex AI)\n",
    "# MODEL_PROVIDER = \"gemini\"\n",
    "# MODEL = \"gemini-2.0-flash-001\"\n",
    "# config.set_google_cloud_config(\"YOUR PROJECT\", \"YOUR LOCATION\")\n",
    "\n",
    "# Set up GPT configuration\n",
    "MODEL_PROVIDER = \"gpt\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "config.set_api_key(\"gpt\", \"YOUR API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define your own formatter function for your data\n",
    "def format_friends_transcript_from_convokit(convo):\n",
    "    utt_lst = convo.get_utterance_ids()\n",
    "    speaker_ids = {}\n",
    "    transcript = \"\"\n",
    "    for utt_id in utt_lst:\n",
    "        utt = corpus.get_utterance(utt_id)\n",
    "        if \"TRANSCRIPT_NOTE\" not in utt.speaker.id:\n",
    "            if utt.speaker.id not in speaker_ids:\n",
    "                speaker_ids[utt.speaker.id] = 1 + len(speaker_ids)\n",
    "            transcript += \"Speaker\"+str(speaker_ids[utt.speaker.id]) + \" : \" + utt.text+ \"\\n\\n\"\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare your own prompt for writing the SCD with your data\n",
    "friends_summary_prompt = \"\"\"\n",
    "Write a short summary capturing the trajectory of a casual conversation. \n",
    "Do not include specific topics, events, or arguments from the conversation. The style you should avoid is illustrated in \n",
    "Example Sentence 1: “Speaker1 said they had a difficult day at work, and mentioned that their boss was unfair. Speaker2 listened and agreed that bosses can be tough, then suggested they go out for dinner to forget about it..” Instead, you should include indicators of sentiments (e.g., warmth, empathy, humor, nostalgia, vulnerability, support), individual intentions (e.g., building rapport, offering reassurance, seeking validation, self-disclosure, active listening, gentle disagreement, creating distance), and conversational strategies (if any) such as “collaborative storytelling,” “inside jokes,” “mirroring emotions,” and “affectionate teasing.” \n",
    "The following sentences demonstrate the style you should follow: \n",
    "Example Sentence 2: “Both speakers have similar feelings and appeared mutually supportive. Speaker1 initiates with a moment of self-disclosure, and Speaker2 responds with empathy and validation. Both speakers build on this exchange, strengthening their rapport.” \n",
    "Example Sentence 3: “The two speakers connected with back-and-forth affectionate teasing. Throughout the conversation, they kept building on each other's humor with playful remarks, creating a lighthearted and comfortable discussion.” Overall, the trajectory summary should capture the key moments where the emotional connection of the conversation notably changes. Here is an example of a complete trajectory summary: The conversation begins with two speakers exchanging neutral, surface-level comments. Speaker1 then shifts the tone by sharing a personal anecdote, prompting Speaker2 to respond with warmth and empathy. Speaker1 elaborates on their story and their need, but Speaker2 does not extend their support but retracts it. \n",
    "Now, provide the trajectory summary for the following conversation. \n",
    "Conversation Transcript: {formatted_object}. \n",
    "Now, summarize this conversation. Remember, do not include specific topics, claims, or arguments from the conversation. Instead, try to capture the speakers' sentiments, intentions, and conversational/persuasive strategies. Limit the trajectory summary to 80 words. \n",
    "Trajectory Summary:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends_sop_prompt = \"\"\"\n",
    "Here is a trajectory summary of a conversation that lays out how the dynamics of the conversation developed. You need to parse the summary into events in order. \n",
    "Follow the following guidelines:\n",
    "1. Try to maintain the original language of the summary as much as you can. \n",
    "2. Provide your output as a Python dictionary with the following structure:\n",
    "_(Note: Do NOT use markdown, JSON formatting, or code block delimiters.)_ \n",
    "{{\n",
    "    '0': \"\" // description of the event\n",
    "    '1': ...\n",
    "    ...\n",
    "}}\n",
    "Here is the summary:\n",
    "{formatted_object}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize your SCD transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_transformer = SCD(\n",
    "        model_provider=MODEL_PROVIDER,\n",
    "        config=config,\n",
    "        model=MODEL,\n",
    "        custom_scd_prompt=friends_summary_prompt,\n",
    "        custom_sop_prompt=friends_sop_prompt,\n",
    "        custom_prompt_dir=\"friends_prompts\",\n",
    "        generate_scd=True,\n",
    "        generate_sop=True,\n",
    "        scd_metadata_name=\"machine_scd\",\n",
    "        sop_metadata_name=\"machine_sop\",\n",
    "        conversation_formatter=format_friends_transcript_from_convokit\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_ids = list(corpus.get_conversation_ids())[:2]\n",
    "selector = lambda conv: conv.id in conversation_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = scd_transformer.transform(corpus, selector=selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCD:  The conversation begins with playful teasing and lighthearted banter, creating a warm atmosphere. As one speaker expresses vulnerability, others respond with empathy and support, fostering a sense of camaraderie. The tone shifts to deeper emotional revelations, with moments of humor interspersed, allowing for self-disclosure and connection. Despite some tension, the group maintains a supportive dynamic, ultimately reinforcing their bonds through shared experiences and gentle encouragement, culminating in a mix of nostalgia and understanding.\n",
      "SoP:  {\n",
      "    '0': \"The conversation begins with playful teasing and lighthearted banter, creating a warm atmosphere.\",\n",
      "    '1': \"As one speaker expresses vulnerability, others respond with empathy and support, fostering a sense of camaraderie.\",\n",
      "    '2': \"The tone shifts to deeper emotional revelations, with moments of humor interspersed, allowing for self-disclosure and connection.\",\n",
      "    '3': \"Despite some tension, the group maintains a supportive dynamic.\",\n",
      "    '4': \"Ultimately reinforcing their bonds through shared experiences and gentle encouragement, culminating in a mix of nostalgia and understanding.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "convo = corpus.get_conversation(conversation_ids[0])\n",
    "print(\"SCD: \", convo.meta[\"machine_scd\"])\n",
    "print(\"SoP: \", convo.meta[\"machine_sop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute ConDynS Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "condyns = ConDynS(model_provider=MODEL_PROVIDER, \n",
    "                  model=MODEL, \n",
    "                  config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConDynS Score between conversations s01_e01_c01_u001 and s01_e01_c02_u001: 0.6499999999999999\n",
      "Score stored in conversation s01_e01_c01_u001 metadata: 0.6499999999999999\n",
      "Score stored in conversation s01_e01_c02_u001 metadata: 0.6499999999999999\n",
      "Score reasoning stored in conversation s01_e01_c01_u001 metadata: [{'0': {'analysis': 'Transcript starts with playful banter but lacks warmth.', 'score': 0.3}, '1': {'analysis': 'Some expressions of vulnerability are present, but empathy is minimal.', 'score': 0.4}, '2': {'analysis': 'Emotional revelations occur, but humor is not well interspersed.', 'score': 0.5}, '3': {'analysis': 'Tension is present, but support is inconsistent.', 'score': 0.4}, '4': {'analysis': 'Shared experiences are mentioned, but bonds are not strongly reinforced.', 'score': 0.3}}, {'0': {'analysis': 'Transcript starts with playful banter about dating, matching the first event.', 'score': 1}, '1': {'analysis': 'Speaker6 expresses vulnerability about a breakup, aligning with the second event.', 'score': 1}, '2': {'analysis': 'Speaker2 offers support to Speaker6, resembling reassurance and validation.', 'score': 0.6}, '3': {'analysis': 'Humor returns as the group shares personal stories, matching the third event.', 'score': 1}, '4': {'analysis': 'Camaraderie is evident throughout, balancing support and humor, fitting the last event.', 'score': 1}}]\n",
      "Score reasoning stored in conversation s01_e01_c02_u001 metadata: [{'0': {'analysis': 'Transcript starts with playful banter but lacks warmth.', 'score': 0.3}, '1': {'analysis': 'Some expressions of vulnerability are present, but empathy is minimal.', 'score': 0.4}, '2': {'analysis': 'Emotional revelations occur, but humor is not well interspersed.', 'score': 0.5}, '3': {'analysis': 'Tension is present, but support is inconsistent.', 'score': 0.4}, '4': {'analysis': 'Shared experiences are mentioned, but bonds are not strongly reinforced.', 'score': 0.3}}, {'0': {'analysis': 'Transcript starts with playful banter about dating, matching the first event.', 'score': 1}, '1': {'analysis': 'Speaker6 expresses vulnerability about a breakup, aligning with the second event.', 'score': 1}, '2': {'analysis': 'Speaker2 offers support to Speaker6, resembling reassurance and validation.', 'score': 0.6}, '3': {'analysis': 'Humor returns as the group shares personal stories, matching the third event.', 'score': 1}, '4': {'analysis': 'Camaraderie is evident throughout, balancing support and humor, fitting the last event.', 'score': 1}}]\n"
     ]
    }
   ],
   "source": [
    "convo_id1 = conversation_ids[0]\n",
    "convo_id2 = conversation_ids[1]\n",
    "\n",
    "# Compare conversations\n",
    "result, condyns_score = condyns.compare_conversations(\n",
    "    corpus=corpus,\n",
    "    convo_id1=convo_id1, \n",
    "    convo_id2=convo_id2,\n",
    "    sop_meta_name=\"machine_sop\",\n",
    "    formatter=format_friends_transcript_from_convokit  # Use our custom formatter\n",
    ")\n",
    "\n",
    "print(f\"ConDynS Score between conversations {convo_id1} and {convo_id2}: {condyns_score}\")\n",
    "\n",
    "convo1 = corpus.get_conversation(convo_id1)\n",
    "convo2 = corpus.get_conversation(convo_id2)\n",
    "\n",
    "score_key1 = f\"condyns_{convo_id1}_{convo_id2}\"\n",
    "result_key1 = f\"condyns_result_{convo_id1}_{convo_id2}\"\n",
    "score_key2 = f\"condyns_{convo_id2}_{convo_id1}\"\n",
    "result_key2 = f\"condyns_result_{convo_id2}_{convo_id1}\"\n",
    "print(f\"Score stored in conversation {convo_id1} metadata: {convo1.meta.get(score_key1)}\")\n",
    "print(f\"Score stored in conversation {convo_id2} metadata: {convo2.meta.get(score_key2)}\")\n",
    "\n",
    "print(f\"Score reasoning stored in conversation {convo_id1} metadata: {convo1.meta.get(result_key1)}\")\n",
    "print(f\"Score reasoning stored in conversation {convo_id2} metadata: {convo2.meta.get(result_key2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
