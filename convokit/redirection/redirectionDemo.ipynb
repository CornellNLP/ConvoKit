{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a0fb8e",
   "metadata": {},
   "source": [
    "# Redirection Demo in US Supreme Court oral arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4894fbb",
   "metadata": {},
   "source": [
    "This notebook demonstrates our redirection framework introduced this paper: **Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy.** In the paper, we define redirection as the extent to which speakers shift the immediate focus of the conversation and applied our measure in the context of long-term messaging therapy. In this demo, we provide an initial exploration into how our redirection framework can be applied in other domains in particular, to a publicly available dataset of U.S. Supreme Court oral arguments (Danescu-Niculescu-Mizil et al., 2012; Chang et al., 2020). Although court proceedings differ from therapy in terms of topics, goals, and interaction styles, their relatively unstructured and dynamic nature enables an initial exploration of how such discussions are redirected.\n",
    "\n",
    "In this setting, we focus on the interactions between justices and lawyers. The power dynamics between these distinct roles reflect the asymmetric relationship between therapists and patients in mental-health domains, where one party generally holds more influence over the direction of the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc154fb",
   "metadata": {},
   "source": [
    "We first install and import all the necessary packages from Convokit including our wrapper models and config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3314f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/vianxnguyen/ConvoKit.git\n",
    "# !pip install -q convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc1290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from convokit import Corpus, download\n",
    "from convokit.redirection.likelihoodModel import LikelihoodModel\n",
    "from convokit.redirection.gemmaLikelihoodModel import GemmaLikelihoodModel\n",
    "from convokit.redirection.redirection import Redirection\n",
    "from convokit.redirection.config import DEFAULT_BNB_CONFIG, DEFAULT_LORA_CONFIG, DEFAULT_TRAIN_CONFIG\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fc4d3",
   "metadata": {},
   "source": [
    "We then download the `supreme-court` corpus we will be using for training and analysis. If you already have the corpus saved locally, you can specify the path to load the corpus from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e4b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you already have the corpus saved locally, load the corpus from the saved path.\n",
    "# DATA_DIR = '/Users/vian/.convokit/downloads/supreme-corpus'\n",
    "# corpus = Corpus(DATA_DIR)\n",
    "\n",
    "# Otherwise download the corpus\n",
    "corpus = Corpus(filename=download('supreme-corpus'))\n",
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f39e0",
   "metadata": {},
   "source": [
    "For the purposes of the demo, we will randomly sample a subset of 50 conversations (~20k utterances) for our analysis. Since in this demonstration, we focus on interactions between two distinct roles of justices and lawyers, we label the speaker role for each utterance (either justice or lawyer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2496d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "convos = [convo for convo in corpus.iter_conversations()]\n",
    "sample_convos = random.sample(convos, 50)\n",
    "print(len(sample_convos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99029a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in sample_convos:\n",
    "  for utt in convo.iter_utterances():\n",
    "    if utt.speaker.id.startswith(\"j_\"):\n",
    "      utt.meta[\"role\"] = \"justice\"\n",
    "    else:\n",
    "      utt.meta[\"role\"] = \"lawyer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b427dbe",
   "metadata": {},
   "source": [
    "We will use a 90/10/10 train/val/test split. We then label the conversations with their corresponding split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ffa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_convos, temp_convos = train_test_split(sample_convos, test_size=0.2, random_state=10)\n",
    "val_convos, test_convos = train_test_split(temp_convos, test_size=0.5, random_state=10)\n",
    "print(len(train_convos), len(val_convos), len(test_convos))\n",
    "\n",
    "for convo in train_convos:\n",
    "  convo.meta[\"train\"] = True\n",
    "for convo in val_convos: \n",
    "  convo.meta[\"val\"] = True \n",
    "for convo in test_convos:\n",
    "  convo.meta[\"test\"] = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1d3c6",
   "metadata": {},
   "source": [
    "Now, we define our likelihood model responsible for computing utterance likelihoods based on provided context.The likelihood probabilities are later used to compute redirection scores for each utterance. Here, we define a likelihood model using the Gemma-2B model called `GemmaLikelihodModel` which inherits from a default `LikelihoodModel` interface. Different models (Gemma, Llama, Mistral, etc.) can be supported by inheriting from this base interface. \n",
    "\n",
    "Since in this demo, we are using Gemma-2B through HuggingFace, we need to provide an authentication token for access to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf38bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_likelihood_model = \\\n",
    "    GemmaLikelihoodModel(\n",
    "        hf_token = \"TODO: ADD HUGGINGFACE AUTH TOKEN\",\n",
    "        model_id = \"google/gemma-2b\", \n",
    "        train_config = DEFAULT_TRAIN_CONFIG,\n",
    "        bnb_config = DEFAULT_BNB_CONFIG,\n",
    "        lora_config = DEFAULT_LORA_CONFIG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d38969",
   "metadata": {},
   "source": [
    "We use the following default configs and parameters for fine-tuning. However, you may override these by defining your own configs and passing them to the `GemmaLikelihoodModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef250fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DEFAULT_BNB_CONFIG = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "DEFAULT_LORA_CONFIG = LoraConfig(\n",
    "    r=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "DEFAULT_TRAIN_CONFIG = {\n",
    "    \"output_dir\": \"checkpoints\",\n",
    "    \"logging_dir\": \"logging\",\n",
    "    \"logging_steps\": 25,\n",
    "    \"eval_steps\": 50, \n",
    "    \"num_train_epochs\": 2, \n",
    "    \"per_device_train_batch_size\": 1,  \n",
    "    \"per_device_eval_batch_size\": 1,   \n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 50,\n",
    "    \"optim\": \"paged_adamw_8bit\",\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"load_best_model_at_end\": True,\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04001232",
   "metadata": {},
   "source": [
    "Now we can define our redirection model, providing the initialized `gemma_likelihood_model` as our `LikelihoodModel`. The `redirection_attribute_name` represents the name of the meta-data field to save our redirection scores to in the corpus.\n",
    "\n",
    "We also note that it is possible to define your own `previous_context_selector` and `future_context_selector` to determine which contexts you would use to compute the likelihoods. The functions take as input an utterance and returns the previous (actual and reference) or future contexts for that particular utterance. By default, we use the immediate contexts described in our paper. Note that the default implementation for these contexts assumes we are working with two distinct speaker roles. You may write your own context selectors to customize them for more than two speaker types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirection = \\\n",
    "    Redirection(\n",
    "        likelihood_model = gemma_likelihood_model,\n",
    "        redirection_attribute_name = \"redirection\"\n",
    "#         previous_context_selector = <YOUR OWN PREVIOUS CONTEXT SELECTOR>, \n",
    "#         future_context_selector = <YOUR OWN FUTURE CONTEXT SELECTOR>,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69928ba4",
   "metadata": {},
   "source": [
    "Now we can call the fit method to fine-tune our model on a subset of the conversations in the corpus. We use a selector function to only fine-tune on the `train` subset of our data. Alternatively, if you already have saved an existing model, you can load it into memory using `load_from_disk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirection.fit(corpus, \n",
    "                      train_selector=lambda convo: \"train\" in convo.meta, \n",
    "                      val_selector=lambda convo: \"val\" in convo.meta\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a5d20",
   "metadata": {},
   "source": [
    "After we have our fine-tuned model, we can then run inference on the test conversations in order to compute the redirection scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f975087",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirection.transform(corpus, selector=lambda convo: \"test\" in convo.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01427de1",
   "metadata": {},
   "source": [
    "We can then call summarize to view examples of high and low redirecting utterances from each speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36bccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirection.summarize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087cfcc0",
   "metadata": {},
   "source": [
    "We can also perform a FightingWords analysis to see distinguishing bigrams indicating high vs. low redirection from both speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48ab266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import FightingWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def9310",
   "metadata": {},
   "source": [
    "We first label top 20% and bottom 20% of utterances from both speakers based on their redirection scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_utts = []\n",
    "lawyer_utts = []\n",
    "\n",
    "for convo in test_convos: \n",
    "  for utt in convo.iter_utterances():\n",
    "    if \"redirection\" in utt.meta:\n",
    "      if utt.meta[\"role\"] == \"justice\":\n",
    "        justice_utts.append(utt)\n",
    "      else:\n",
    "        lawyer_utts.append(utt)\n",
    "\n",
    "justice_utts = sorted(justice_utts, key=lambda utt: utt.meta[\"redirection\"])\n",
    "lawyer_utts = sorted(lawyer_utts, key=lambda utt: utt.meta[\"redirection\"])\n",
    "\n",
    "justice_threshold = int(len(justice_utts) * 0.20)\n",
    "lawyer_threshold = int(len(lawyer_utts) * 0.20)\n",
    "\n",
    "for utt in justice_utts[:justice_threshold]:\n",
    "  utt.meta['type'] = \"justice_low\"\n",
    "for utt in justice_utts[-justice_threshold:]:\n",
    "  utt.meta['type'] = \"justice_high\"\n",
    "\n",
    "for utt in lawyer_utts[:lawyer_threshold]:\n",
    "  utt.meta['type'] = \"lawyer_low\"\n",
    "for utt in lawyer_utts[-lawyer_threshold:]:\n",
    "  utt.meta['type'] = \"lawyer_high\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33167261",
   "metadata": {},
   "source": [
    "Here we first show phrasings indicative of low redirection from justices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbe4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_justice = FightingWords(ngram_range=(2,2))\n",
    "class1 = 'justice_high'\n",
    "class2 = 'justice_low'\n",
    "fw_justice.fit(corpus, class1_func=lambda utt: 'type' in utt.meta and utt.meta['type'] == class1, \n",
    "               class2_func=lambda utt: 'type' in utt.meta and utt.meta['type'] == class2)\n",
    "justice = fw_justice.summarize(corpus, plot=False, class1_name=class1, class2_name=class2)\n",
    "justice.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816627d",
   "metadata": {},
   "source": [
    "Here we show phrasings indicative of high redirection from justices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad93c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "justice.tail(20)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34287b06",
   "metadata": {},
   "source": [
    "We can perform the corresponding analysis for lawyers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c101e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_lawyer = FightingWords(ngram_range=(2,2))\n",
    "class1 = 'lawyer_high'\n",
    "class2 = 'lawyer_low'\n",
    "fw_lawyer.fit(corpus, class1_func=lambda utt: 'type' in utt.meta and utt.meta['type'] == class1, \n",
    "               class2_func=lambda utt: 'type' in utt.meta and utt.meta['type'] == class2)\n",
    "lawyer = fw_lawyer.summarize(corpus, plot=False, class1_name=class1, class2_name=class2)\n",
    "lawyer.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe98f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lawyer.tail(20)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39208446",
   "metadata": {},
   "source": [
    "We can also compare the average redirection between justices and lawyers in the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_justices = []\n",
    "convo_lawyers = []\n",
    "for convo in test_convos: \n",
    "    justice = []\n",
    "    lawyer = []\n",
    "    for utt in convo.iter_utterances():\n",
    "        if \"redirection\" in utt.meta:\n",
    "            if utt.meta[\"role\"] == \"justice\":\n",
    "                justice.append(utt)\n",
    "            else:\n",
    "                lawyer.append(utt)\n",
    "    convo_justices.append(np.mean(justice))\n",
    "    convo_lawyers.append(np.mean(lawyer))\n",
    "    \n",
    "print(\"Average justice:\", np.mean(convo_justices))\n",
    "print(\"Average lawyer:\", np.mean(convo_lawyers))\n",
    "stat, p_value = wilcoxon(convo_justices, convo_lawyers)\n",
    "print(f\"Statistic: {stat}, P-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
