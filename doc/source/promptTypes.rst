Prompt Types
============


Note: this is an older method that we keep in the ConvoKit library to reflect the content of past publications, and for backwards compatability. For a modified and more general variant of the method, see the `ExpectedContextModel functionality <https://convokit.cornell.edu/documentation/expected_context_model.html>`_.

Implements prompt type model described in this `paper <http://www.cs.cornell.edu/~cristian/Asking_too_much.html>`_.



Example usage: 
`end to end pipeline to infer question types in British parliament <https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/prompt-types/prompt-type-wrapper-demo.ipynb>`_, 
`more detailed exploration of additional options for using the module <https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/prompt-types/prompt-type-demo.ipynb>`_, `understanding the use of conversational prompts in conversations gone awry on Wikipedia <https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/conversations-gone-awry/Conversations_Gone_Awry_Prediction.ipynb>`_.

.. automodule:: convokit.prompt_types.promptTypes
	:members:

.. automodule:: convokit.prompt_types.promptTypeWrapper
	:members: