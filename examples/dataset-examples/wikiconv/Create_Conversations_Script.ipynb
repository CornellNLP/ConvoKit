{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiConv Create Conversations\n",
    "\n",
    "This notebook provides different forms of conversations from  the Wikiconv data set. In particular, it showcases the final version of selected conversations and how that conversation developed over time. It also provides a framework to print out rnadomly selected final conversations and the corresponding wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant modules\n",
    "from datetime import datetime, timedelta\n",
    "from convokit import Corpus, download\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/seanzhangkx/.convokit/downloads/wikiconv-2003\n"
     ]
    }
   ],
   "source": [
    "# Load the 2003 wikiconv corpus (feel free to change this to a year of your preference)\n",
    "wikiconv_corpus = Corpus(filename=download('wikiconv-2003'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic facts about this subset of the corpus: 91,787 conversations and 140,265 utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91787"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(wikiconv_corpus.iter_conversations()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140265"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(wikiconv_corpus.iter_utterances()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the corpus, we will randomly select conversations to print out based on a few metrics:\n",
    "1. number_of_conversations - how many conversations we want to print out\n",
    "2. conversation_min_length -  the minimum number of utterances we want in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly chooses the set number of conversations to print from the entire conversaton set\n",
    "def print_random_conversations(conversation_list, number_of_conversations, conversation_min_length,  conversation_corpus): \n",
    "    randomly_generated_conversation_list = []\n",
    "    while (len(randomly_generated_conversation_list) != number_of_conversations):\n",
    "        new_conversation = random.randint(0, (len(conversation_list)-1))\n",
    "        new_conversation_id = conversation_list[new_conversation]\n",
    "        conversation_ids_list = new_conversation_id.get_utterance_ids()\n",
    "        if (new_conversation not in randomly_generated_conversation_list \n",
    "            and (len(conversation_ids_list) >= conversation_min_length)):\n",
    "            randomly_generated_conversation_list.append(new_conversation_id)\n",
    "        \n",
    "    return randomly_generated_conversation_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll get a set of random conversatinos from the corpus based on our specifications (print out 3, conversations, with a minimum length of 2) and the output will be a set of serialized conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7fe2586ef280>, 'id': '1172638.641.641', 'meta': ConvoKitMeta({'page_id': '253576', 'page_title': 'Roman Catholic Archdiocese of Quebec', 'page_type': 'talk'})}), Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7fe2586ef280>, 'id': '691102.8439.8439', 'meta': ConvoKitMeta({'page_id': '178863', 'page_title': 'Jimfbleak', 'page_type': 'user_talk'})}), Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7fe2586ef280>, 'id': '490071.18706.18706', 'meta': ConvoKitMeta({'page_id': '14218', 'page_title': 'Homophobia/Archive 6', 'page_type': 'talk'})})]\n"
     ]
    }
   ],
   "source": [
    "conversation_list = list(wikiconv_corpus.iter_conversations())\n",
    "number_of_conversations_to_print = 3\n",
    "conversation_min_length = 2\n",
    "\n",
    "random_conversations = print_random_conversations(conversation_list, number_of_conversations_to_print,\n",
    "                                                     conversation_min_length, wikiconv_corpus)\n",
    "print (random_conversations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, stored in the conversation meta data is the wikipedia information from the page that this conversation is from.\n",
    "We will find that information and print out the link to the associated wikipedia page for each conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=talk:Roman_Catholic_Archdiocese_of_Quebec\n",
      "https://en.wikipedia.org/w/index.php?title=user_talk:Jimfbleak\n",
      "https://en.wikipedia.org/w/index.php?title=talk:Homophobia/Archive_6\n"
     ]
    }
   ],
   "source": [
    "def wikipedia_link_info(conversation):\n",
    "    page_title = conversation.meta['page_title']\n",
    "    page_title = re.sub('\\s+', '_', page_title)\n",
    "    page_type = conversation.meta['page_type']\n",
    "    link_value = \"https://en.wikipedia.org/w/index.php?title=\"+page_type+\":\"+page_title\n",
    "    \n",
    "    return link_value\n",
    "\n",
    "for conversation in random_conversations:\n",
    "    print(wikipedia_link_info(conversation))\n",
    "    conversation_ids_list = conversation.get_utterance_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the conversation and the actual wikipedia page where they exist, we will want to print out the conversation's final form from the utterance data. But to do this, first we will need to compute the correct order of the comments. \n",
    "\n",
    "The corpus functionality does not guarantee the comments are in the right order, so we will compute this flow now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For any comments that do not have matching reply to ids, sort these comments in order of recency \n",
    "def sort_by_timestamp(conversation_ids_list, conversation_corpus):\n",
    "    list_of_utterances = []\n",
    "    for id_val in conversation_ids_list:\n",
    "        utterance_value = conversation_corpus.get_utterance(id_val)\n",
    "        timestamp_val = utterance_value.timestamp\n",
    "        tuple_val = (id_val, timestamp_val)\n",
    "        list_of_utterances.append(tuple_val)\n",
    "\n",
    "    sorted_utterance_list = sorted(list_of_utterances, key = lambda x:x[1])\n",
    "    sorted_utterance_list.reverse()\n",
    "    id_list = [i[0] for i in sorted_utterance_list]\n",
    "    return (id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find cases in which an utterance's reply to is to a comment in the chain that has been modified, deleted or restored\n",
    "def check_lists_for_match(x, conversation_ids_list, utterance, next_utterance_value, conversation_corpus):\n",
    "    modification_list = utterance.meta['modification']\n",
    "    deletion_list = utterance.meta['deletion']\n",
    "    restoration_list = utterance.meta['restoration']\n",
    "    if (len(modification_list)>0):\n",
    "        for utterance_val in modification_list:\n",
    "            if (utterance_val['id'] == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)\n",
    "    if (len(deletion_list)>0):\n",
    "        for utterance_val in deletion_list:\n",
    "            if (utterance_val['id'] == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)\n",
    "    if (len(restoration_list)>0):\n",
    "        for utterance_val in restoration_list:\n",
    "            if (utterance_val['id'] == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the conversation flow correctly and add utterances if the reply-to id matches the current utterance in the list\n",
    "def add_utterance(conversation_ids_list, next_utterance_value, conversation_corpus):\n",
    "    if next_utterance_value.id in conversation_ids_list:\n",
    "        return conversation_ids_list\n",
    "    elif (next_utterance_value.reply_to is None):\n",
    "        conversation_ids_list.append(next_utterance_value.id)\n",
    "    else:\n",
    "        for x in range(0,len(conversation_ids_list)):\n",
    "            utterance_id = conversation_ids_list[x]\n",
    "            if (utterance_id == next_utterance_value.reply_to):\n",
    "                conversation_ids_list.insert(x+1, next_utterance_value.id)\n",
    "            else:\n",
    "                check_lists_for_match(x, conversation_ids_list, conversation_corpus.get_utterance(utterance_id), next_utterance_value, conversation_corpus)\n",
    "\n",
    "    return conversation_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The order of the returned conversation ids is not guaranteed; compute the correct ordering \n",
    "def find_correct_order(conversation_ids_list, conversation_corpus):\n",
    "    correct_list_order = []\n",
    "    #if the conversation has only one comment, return the conversation list\n",
    "    if (len(conversation_ids_list) == 1 ):\n",
    "        return conversation_ids_list\n",
    "\n",
    "    #When the conversation has more than one comment, find the correct order of the comments\n",
    "    if (len(conversation_ids_list) >1):\n",
    "        #Implement a fail safe to efficiently sort \n",
    "        number_of_iterations = 0\n",
    "        while (number_of_iterations <20 and len(correct_list_order) != len(conversation_ids_list)):\n",
    "            for utterance_id in conversation_ids_list:\n",
    "                correct_list_order = add_utterance(correct_list_order, conversation_corpus.get_utterance(utterance_id), conversation_corpus)\n",
    "            number_of_iterations+=1\n",
    "\n",
    "        #In some of the conversations, new utterances will be added that don't reply directly to the current conversation\n",
    "        #Instead, these new utterances are part of the topic at hand (under the same conversation root) and are sorted by recency\n",
    "        if (len(correct_list_order) != len(conversation_ids_list)):\n",
    "            difference_in_sets = set(conversation_ids_list).difference(correct_list_order)\n",
    "            timestamp_sorted_difference = sort_by_timestamp(list(difference_in_sets), conversation_corpus)\n",
    "            correct_list_order.extend(timestamp_sorted_difference)\n",
    "    return correct_list_order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, we can compute the correct order of utterances in each randomly selected conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Order of IDs:['1172638.641.641', '1173000.1045.1045']\n",
      "Correct Order of IDs:['1172638.641.641', '1173000.1045.1045']\n",
      "\n",
      "\n",
      "Original Order of IDs:['811685.0.8439', '811685.0.8612']\n",
      "Correct Order of IDs:['811685.0.8439', '811685.0.8612']\n",
      "\n",
      "\n",
      "Original Order of IDs:['709021.8491.9368', '709021.8654.11099']\n",
      "Correct Order of IDs:['709021.8491.9368', '709021.8654.11099']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for conversation in random_conversations:\n",
    "    conversation_ids_list = conversation.get_utterance_ids()\n",
    "    print ('Original Order of IDs:' + str(conversation_ids_list))\n",
    "    print('Correct Order of IDs:' + str(find_correct_order(conversation_ids_list, wikiconv_corpus)))\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the final form of the conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the conversation text from the list of conversation ids\n",
    "def print_final_conversation(random_conversations, conversation_corpus):\n",
    "    for conversation in random_conversations:\n",
    "        print(wikipedia_link_info(conversation))\n",
    "        conversation_ids_list = conversation.get_utterance_ids()\n",
    "        #First correctly reorder the comments\n",
    "        ordered_list = find_correct_order(conversation_ids_list, conversation_corpus)\n",
    "        #For each utterance, print the text present if the utterance has not been deleted\n",
    "        for utterance_id in ordered_list:\n",
    "            utterance_value = conversation_corpus.get_utterance(utterance_id)\n",
    "            if (utterance_value.text != \" \"):\n",
    "                print (utterance_value.text)\n",
    "                date_time_val = datetime.fromtimestamp(utterance_value.timestamp).strftime('%H:%M %d-%m-%Y')\n",
    "                formatted_user_name = \"--\" + str(utterance_value.speaker.id) + \"  \" + str(date_time_val)\n",
    "                print (formatted_user_name)\n",
    "        print ('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=talk:Roman_Catholic_Archdiocese_of_Quebec\n",
      "Two problems with the title:\n",
      "1) it should not be capitalized;\n",
      "2) all the archbishops are also bishops (for example, the list at Diocese de Montreal lists a particular one as \"third bishop and first archbishop\").\n",
      "I had moved this to List of Roman Catholic bishops of Quebec, and likewise for the Montreal list, but efghij moved them back. May I ask why? - \n",
      "--Montrealais  11:41 20-07-2003\n",
      "1) It should be capitalized. \"Bishop of Quebec\" is a title, just like \"Prime Minister of Canada\" or \"King of Spain\".\n",
      "2) It's technically correct that all archbishops are also bishops, however it is somewhat counter-intuatve to list them all under \"Bishops of Quebec\".\n",
      "-  19:00 20 Jul 2003 (UTC)\n",
      "--Efghij  15:00 20-07-2003\n",
      "\n",
      "\n",
      "\n",
      "https://en.wikipedia.org/w/index.php?title=user_talk:Jimfbleak\n",
      "\n",
      "\n",
      "\n",
      "https://en.wikipedia.org/w/index.php?title=talk:Homophobia/Archive_6\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_final_conversation(random_conversations,  wikiconv_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a compact method to change the default values easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_defaults_print_final(conversation_list, number_of_conversations, conversation_min_length,  \n",
    "                                conversation_corpus):\n",
    "    random_conversations = print_random_conversations(conversation_list, number_of_conversations_to_print,\n",
    "                                                     conversation_min_length, wikiconv_corpus)\n",
    "    print_final_conversation(random_conversations, conversation_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=user_talk:Daniel_C._Boyer/archive_1\n",
      "Have you written this article? or do you have any idea about this article? (If you don't understand Korean, the title means \"unmarried girl backdoor\" or something.) Is it one of your work? \n",
      "--217.0.84.251  15:36 07-04-2003\n",
      "Yes; it should be The Tailgating Spinster (title of my book of poetry).  I apologise if my Korean is not good enough; perhaps you could provide a better translation of the title.  \n",
      "--Daniel C. Boyer  10:47 09-04-2003\n",
      "OK. I'll try to find a better translation. But due to my poor english, I can't understand the title. Does Tailgating mean ''chasing closely''? And does Spinster mean ''unmarried old woman''? \n",
      "--Xaos~enwiki  23:02 09-04-2003\n",
      "Yes; \"tailgating\" means (when one is driving) to follow too closely behind the car (or truck) in front of you.  A spinster is usually used to mean an ''unmaried old woman'' but it can mean an unmarried woman of any age (probably she would have to be old enough to be able to get married to qualify as a spinster).   19:43 Apr 10, 2003 (UTC)\n",
      "--Daniel C. Boyer  15:43 10-04-2003\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_list = list(wikiconv_corpus.iter_conversations())\n",
    "number_of_conversations_to_print = 1\n",
    "conversation_min_length = 2\n",
    "#Refresher on where the wikiconv_corpus  is defined\n",
    "# corpus_path = \"/Users/adityajha/Desktop/ConvoKit-master/second_set/conversation_corpus_year_2015\"\n",
    "# wikiconv_corpus = Corpus(filename=corpus_path)\n",
    "\n",
    "change_defaults_print_final(conversation_list, number_of_conversations_to_print, conversation_min_length,\n",
    "                            wikiconv_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a method to print out the final comment and the intermediate steps in the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_changes_by_timestamp(modification_list, deletion_list, restoration_list,  original_utterance):\n",
    "    text_time_tuple_list = []\n",
    "    if (original_utterance is not None):\n",
    "        text_time_original  = (original_utterance['text'],original_utterance['timestamp'],\n",
    "                           original_utterance['speaker.id'], 'original')\n",
    "        text_time_tuple_list.append(text_time_original)\n",
    "        \n",
    "\n",
    "    for utterance in modification_list:\n",
    "        text_time= (utterance['text'], utterance['timestamp'],\n",
    "                    utterance['speaker.id'], 'modification')\n",
    "        text_time_tuple_list.append(text_time)\n",
    "    \n",
    "    for utterance in deletion_list:\n",
    "        text_time= ('', utterance['timestamp'],\n",
    "                    utterance['speaker.id'], 'deletion')\n",
    "        text_time_tuple_list.append(text_time)\n",
    "        \n",
    "    for utterance in restoration_list:\n",
    "        text_time= (utterance['text'], utterance['timestamp'],\n",
    "                    utterance['speaker.id'], 'restoration')\n",
    "        text_time_tuple_list.append(text_time)\n",
    "            \n",
    "    text_time_tuple_list.sort(key=lambda x: x[1])\n",
    "    #text_time_tuple_list.reverse()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return text_time_tuple_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_intermediate_conversation(random_conversations, conversation_corpus):\n",
    "    for conversation in random_conversations:\n",
    "        conversation_ids_list = conversation.get_utterance_ids()\n",
    "        #First correctly reorder the comments\n",
    "        ordered_list = find_correct_order(conversation_ids_list, conversation_corpus)\n",
    "        #For each utterance, print the text present if the utterance has not been deleted\n",
    "        for utterance_id in ordered_list:\n",
    "            utterance_value = conversation_corpus.get_utterance(utterance_id)\n",
    "            if (utterance_value.text != \" \"):\n",
    "                final_comment =  utterance_value.text\n",
    "                date_time_val = datetime.fromtimestamp(utterance_value.timestamp).strftime('%H:%M %d-%m-%Y')\n",
    "                formatted_user_name = \"--\" + str(utterance_value.speaker.id) + \"  \" + str(date_time_val)\n",
    "                \n",
    "        \n",
    "                final_timestamp = utterance_value.timestamp\n",
    "                modification_list = utterance_value.meta['modification']\n",
    "                deletion_list = utterance_value.meta['deletion']\n",
    "                restoration_list = utterance_value.meta['restoration']\n",
    "                \n",
    "                sorted_timestamps = sort_changes_by_timestamp(modification_list, deletion_list, restoration_list,\n",
    "                                                             utterance_value.meta['original'])\n",
    "                \n",
    "                if (len(sorted_timestamps)>0):\n",
    "                    print(wikipedia_link_info(conversation))\n",
    "                    print ('Final Comment')\n",
    "                    print (final_comment)\n",
    "                    print (formatted_user_name)\n",
    "                    \n",
    "                    for value in sorted_timestamps:\n",
    "                        print ('\\n')\n",
    "                        print (value[3])\n",
    "                        print (value[0])\n",
    "                        formatted_user_name = \"--\" + str(value[2]) + \"  \" + str(datetime.fromtimestamp(float(value[1])).strftime('%H:%M %d-%m-%Y'))\n",
    "                        #str(datetime.fromtimestamp(value[1]).strftime('%H:%M %d-%m-%Y'))\n",
    "                        print (formatted_user_name)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method to quikcly print out intermediate conversations defined below (only conversations with modification, deletion and restoration conversations  are shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_defaults_print_intermediate(conversation_list, number_of_conversations, conversation_min_length,  \n",
    "                                conversation_corpus):\n",
    "    random_conversations = print_random_conversations(conversation_list, number_of_conversations_to_print,\n",
    "                                                     conversation_min_length, wikiconv_corpus)\n",
    "    print_intermediate_conversation(random_conversations, conversation_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the flow of different conversations  is shown with the final comment first displayed and the corresponding actions that have occurred from earliest to latest actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/index.php?title=user_talk:Alex756/Archive\n",
      "Final Comment\n",
      " Points of order \n",
      "--142.177.103.185  19:51 13-10-2003\n",
      "\n",
      "\n",
      "original\n",
      " Points of order \n",
      "--142.177.78.145  19:38 13-10-2003\n",
      "\n",
      "\n",
      "deletion\n",
      "\n",
      "--MartinHarper  19:40 13-10-2003\n",
      "\n",
      "\n",
      "restoration\n",
      " Points of order \n",
      "--142.177.103.185  19:51 13-10-2003\n"
     ]
    }
   ],
   "source": [
    "conversation_list = list(wikiconv_corpus.iter_conversations())\n",
    "number_of_conversations_to_print = 10\n",
    "conversation_min_length = 3\n",
    "\n",
    "change_defaults_print_intermediate(conversation_list, number_of_conversations_to_print, conversation_min_length,\n",
    "                            wikiconv_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64088027e7c0a20d63d62220dce553b4ec4f0843d40501e1a870b5ac3ef9bde3"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
