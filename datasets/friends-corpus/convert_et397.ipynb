{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_YNRDvb3etb"
   },
   "source": [
    "# Converting the Friends dataset into ConvoKit format\n",
    "\n",
    "This notebook describes how we converted the Friends dataset (https://github.com/emorynlp/character-mining) into a Corpus with ConvoKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Wp3WIlBN4D7l",
    "outputId": "77391cf8-1ce6-4b0c-977e-d8bfdfa54729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting convokit\n",
      "Collecting scikit-learn>=0.20.0 (from convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/57/8a9889d49d0d77905af5a7524fb2b468d2ef5fc723684f51f5ca63efed0d/scikit_learn-0.21.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting dill==0.2.9 (from convokit)\n",
      "Collecting pandas>=0.23.4 (from convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/39/73/99aa822ee88cef5829607217c11bf24ecc1171ae5d49d5f780085f5da518/pandas-0.25.1-cp37-cp37m-macosx_10_9_x86_64.macosx_10_10_x86_64.whl\n",
      "Collecting spacy==2.0.12 (from convokit)\n",
      "Collecting msgpack-numpy==0.4.3.2 (from convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/45/464be6da85b5ca893cfcbd5de3b31a6710f636ccb8521b17bd4110a08d94/msgpack_numpy-0.4.3.2-py2.py3-none-any.whl\n",
      "Collecting matplotlib>=3.0.0 (from convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/8b/af9e0984f5c0df06d3fab0bf396eb09cbf05f8452de4e9502b182f59c33b/matplotlib-3.1.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting nltk>=3.4 (from convokit)\n",
      "Collecting scipy>=1.1.0 (from convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/d5/06/1a696649f4b2e706c509cb9333fdc6331fbe71251cede945f9e1fa13ea34/scipy-1.3.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting numpy>=1.11.0 (from scikit-learn>=0.20.0->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/e8/5ececadd9cc220bb783b4ce6ffaa9266925d37ed41237bc23bc530ab4f3d/numpy-1.17.2-cp37-cp37m-macosx_10_6_intel.whl\n",
      "Collecting joblib>=0.11 (from scikit-learn>=0.20.0->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl\n",
      "Collecting pytz>=2017.2 (from pandas>=0.23.4->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/87/76/46d697698a143e05f77bec5a526bf4e56a0be61d63425b68f4ba553b51f2/pytz-2019.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas>=0.23.4->convokit) (2.8.0)\n",
      "Collecting preshed<2.0.0,>=1.0.0 (from spacy==2.0.12->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/71/60659082ccb54d6bc2b9420d0f95c2a2c7423ce0777f9305723145c11f35/preshed-1.0.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting plac<1.0.0,>=0.9.6 (from spacy==2.0.12->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
      "Collecting cymem<1.32,>=1.30 (from spacy==2.0.12->convokit)\n",
      "Collecting ujson>=1.35 (from spacy==2.0.12->convokit)\n",
      "Collecting thinc<6.11.0,>=6.10.3 (from spacy==2.0.12->convokit)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy==2.0.12->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting murmurhash<0.29,>=0.28 (from spacy==2.0.12->convokit)\n",
      "Collecting regex==2017.4.5 (from spacy==2.0.12->convokit)\n",
      "Collecting msgpack>=0.3.0 (from msgpack-numpy==0.4.3.2->convokit)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.0.0->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=3.0.0->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/df/93/8bc9b52a8846be2b9572aa0a7c881930939b06e4abe1162da6a0430b794f/kiwisolver-1.1.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib>=3.0.0->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/11/fa/0160cd525c62d7abd076a070ff02b2b94de589f1a9789774f17d7c54058e/pyparsing-2.4.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /Users/emilytseng/Library/Python/3.7/lib/python/site-packages (from nltk>=3.4->convokit) (1.12.0)\n",
      "Collecting cytoolz<0.10,>=0.9.0 (from thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit)\n",
      "Collecting wrapt<1.11.0,>=1.10.0 (from thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit)\n",
      "Collecting tqdm<5.0.0,>=4.10.0 (from thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/88/d3213e2f3492daf09d8b41631ad6899f56db17ce83ea9c8a579902bafe5e/tqdm-4.35.0-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl\n",
      "Collecting idna<2.9,>=2.5 (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy==2.0.12->convokit)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/certifi-2019.9.11-py2.py3-none-any.whl (154kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.0->convokit) (41.0.1)\n",
      "Collecting toolz>=0.8.0 (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy==2.0.12->convokit)\n",
      "Installing collected packages: numpy, scipy, joblib, scikit-learn, dill, pytz, pandas, cymem, preshed, plac, ujson, msgpack, toolz, cytoolz, wrapt, msgpack-numpy, murmurhash, tqdm, thinc, chardet, urllib3, idna, certifi, requests, regex, spacy, cycler, kiwisolver, pyparsing, matplotlib, nltk, convokit\n",
      "  Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed certifi-2019.9.11 chardet-3.0.4 convokit-2.0.11 cycler-0.10.0 cymem-1.31.2 cytoolz-0.9.0.1 dill-0.2.9 idna-2.8 joblib-0.13.2 kiwisolver-1.1.0 matplotlib-3.1.1 msgpack-0.6.1 msgpack-numpy-0.4.3.2 murmurhash-0.28.0 nltk-3.4.5 numpy-1.17.2 pandas-0.25.1 plac-0.9.6 preshed-1.0.1 pyparsing-2.4.2 pytz-2019.2 regex-2017.4.5 requests-2.22.0 scikit-learn-0.21.3 scipy-1.3.1 spacy-2.0.12 thinc-6.10.3 toolz-0.10.0 tqdm-4.35.0 ujson-1.35 urllib3-1.25.3 wrapt-1.10.11\n",
      "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K     |████████████████████████████████| 37.4MB 8.9MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/rb/gnb30d2s5ls0jdfrx8frt7_h0000gp/T/pip-ephem-wheel-cache-dfzzk81y/wheels/54/7c/d8/f86364af8fbba7258e14adae115f18dd2c91552406edc3fdaa\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "    /usr/local/lib/python3.7/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip3 install convokit\n",
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXk4Biep3xHH"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from convokit import Corpus, User, Utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmw72j5J44E4"
   },
   "source": [
    "## The Friends Dataset\n",
    "\n",
    "The original dataset (https://github.com/emorynlp/character-mining) contains a set of 10 JSON files, each of which represents a complete transcript of 1 season of <i>Friends</i>. Since the data are available in JSON format from this GitHub repo, we download the raw data directly using the `requests` module. You will not need to download raw data files to use this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7CI3mm378N8"
   },
   "source": [
    "## Gather information about the corpus\n",
    "For the **corpus.json** file, it will include information of number of episodes, number of scenes, number of utterances and number of speakers.\n",
    "When counting the number of utterances, we ignore utterances that have no conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xN79FO2u6B8q"
   },
   "outputs": [],
   "source": [
    "num_episodes = 0\n",
    "num_scenes = 0\n",
    "num_utterances = 0\n",
    "speakers = set()\n",
    "for i in range(1,11):\n",
    "  season_number = '0'+str(i) if i < 10 else '10'\n",
    "  json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_'+str(season_number)+'.json'\n",
    "  r = requests.get(json_file)\n",
    "  \n",
    "  season = json.loads(r.text)\n",
    "  episodes = season['episodes']\n",
    "  num_episodes += len(episodes)\n",
    "  for j in range(len(episodes)):\n",
    "    episode = episodes[j]\n",
    "    scenes = episode['scenes']\n",
    "    num_scenes += len(scenes)\n",
    "    for k in range(len(scenes)):\n",
    "      scene = scenes[k]\n",
    "      utterances = scene['utterances']\n",
    "      for l in range(len(utterances)):\n",
    "        utterance = utterances[l]\n",
    "        speaker = utterance['speakers']\n",
    "        speakers.update(speaker)\n",
    "        num_utterances += 1 if len(speaker) != 0 else 0\n",
    "corpus = {'friends': 'friends corpus', 'num_episodes': num_episodes, 'num_scenes': num_scenes, 'num_utterances': num_utterances, 'num_speakers': len(speakers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "o827biTbBtlu",
    "outputId": "f85449cf-cded-4229-e5af-b7add85f2a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'friends': 'friends corpus', 'num_episodes': 236, 'num_scenes': 3107, 'num_utterances': 61338, 'num_speakers': 700}\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxhlL6aNCvxr"
   },
   "source": [
    "## Generating user information\n",
    "Since our dataset doesn't have any existing user information, we extract speaker information from the conversation. For each user, we collect the episode in which he/she first appears and guess his/her gender based on the name using the gender_guesser module.\n",
    "\n",
    "For each user, we create an object with:\n",
    "\n",
    "- <b>name:</b> the name of the character\n",
    "- <b>first_appearance:</b> the episode in which he or she first appeared\n",
    "- <b>gender:</b> the character's gender, as defined by the `gender_guesser` module's guess of his/her name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "sw_7_7YJMIWp",
    "outputId": "fb1f6b61-5b5e-4c18-8b08-7db8fca4e39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gender_guesser\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/fb/3f2aac40cd2421e164cab1668e0ca10685fcf896bd6b3671088f8aab356e/gender_guesser-0.4.0-py2.py3-none-any.whl (379kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: gender-guesser\n",
      "Successfully installed gender-guesser-0.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install gender_guesser\n",
    "import gender_guesser.detector as gender\n",
    "d = gender.Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjNZT57Qv7Vd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "users = {}\n",
    "for i in tqdm(range(1,11)):\n",
    "  season_number = '0'+str(i) if i < 10 else '10'\n",
    "  json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_'+str(season_number)+'.json'\n",
    "  r = requests.get(json_file)\n",
    "  \n",
    "  season = json.loads(r.text)\n",
    "  episodes = season['episodes']\n",
    "  for j in range(len(episodes)):\n",
    "    episode = episodes[j]\n",
    "    scenes = episode['scenes']\n",
    "    for k in range(len(scenes)):\n",
    "      scene = scenes[k]\n",
    "      utterances = scene['utterances']\n",
    "      for l in range(len(utterances)):\n",
    "        utterance = utterances[l]\n",
    "        speaker_list = utterance['speakers']\n",
    "        for speaker in speaker_list:\n",
    "          if speaker not in users:\n",
    "            users[speaker] = {'first_appearance': episode['episode_id'], 'gender': d.get_gender(speaker.split()[0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJqo7WSSCua1"
   },
   "source": [
    "Sanity-checking the user data, we should see the correct genders assigned to the 6 friends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "YeKBCPZqCMeH",
    "outputId": "3fd779d3-eda9-424d-e032-64a3034665bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users in the data = 700/700\n",
      "Monica Geller object:  {'first_appearance': 's01_e01', 'gender': 'female'}\n",
      "Joey Tribbiani object:  {'first_appearance': 's01_e01', 'gender': 'male'}\n",
      "Chandler Bing object:  {'first_appearance': 's01_e01', 'gender': 'mostly_male'}\n",
      "Phoebe Buffay object:  {'first_appearance': 's01_e01', 'gender': 'female'}\n",
      "Ross Geller object:  {'first_appearance': 's01_e01', 'gender': 'male'}\n",
      "Rachel Green object:  {'first_appearance': 's01_e01', 'gender': 'female'}\n"
     ]
    }
   ],
   "source": [
    "print(\"number of users in the data = {}/700\".format(len(users)))\n",
    "print(\"Monica Geller object: \", users[\"Monica Geller\"])\n",
    "print(\"Joey Tribbiani object: \", users[\"Joey Tribbiani\"])\n",
    "print(\"Chandler Bing object: \", users[\"Chandler Bing\"])\n",
    "print(\"Phoebe Buffay object: \", users[\"Phoebe Buffay\"])\n",
    "print(\"Ross Geller object: \", users[\"Ross Geller\"])\n",
    "print(\"Rachel Green object: \", users[\"Rachel Green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Csa06wuFh8U"
   },
   "source": [
    "We then create a User object for each unique character in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xs7QjJJJFg2S"
   },
   "outputs": [],
   "source": [
    "corpus_users = {k: User(name=k, meta=v) for k,v in users.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cfMxU1u_GJD7",
    "outputId": "c1a29dd9-a2b9-4832-c1d0-10a94e86aae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monica Geller\n",
      "{'first_appearance': 's01_e01', 'gender': 'female'}\n"
     ]
    }
   ],
   "source": [
    "print(corpus_users['Monica Geller'].name)\n",
    "print(corpus_users['Monica Geller'].meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tJ_9BMXFygP"
   },
   "source": [
    "## Generating Utterances\n",
    "\n",
    "We then loop through the data to generate a list of all utterances in the series. To align with the Utterance schema ConvoKit expects, we construct for each utterance:\n",
    "\n",
    "- **id:** index of the utterance\n",
    "\n",
    "- **user:** the user who authored the utterance; the speaker in our case\n",
    "\n",
    "- **root:** id of the conversation root of the utterance; the scene id in our case\n",
    "\n",
    "- **reply_to:** id of the utterance to which this utterance replies to; None if the utterance is not a reply. The previous speaker, to simplify the process.\n",
    "\n",
    "- **timestamp:** time of the utterance\n",
    "\n",
    "- **text:** textual content of the utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "MDgFZjF6GN3O",
    "outputId": "df2c3b44-537d-4b73-cbbc-7bbea4d0eac3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "all_utterances = {}\n",
    "\n",
    "for i in tqdm(range(1,11)):\n",
    "  season_number = '0'+str(i) if i < 10 else '10'\n",
    "  json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_'+str(season_number)+'.json'\n",
    "  r = requests.get(json_file)\n",
    "  \n",
    "  season = json.loads(r.text)\n",
    "  episodes = season['episodes']\n",
    "  for j in range(len(episodes)):\n",
    "    episode = episodes[j]\n",
    "    scenes = episode['scenes']\n",
    "    for k in range(len(scenes)):\n",
    "      scene = scenes[k]\n",
    "      utterances = scene['utterances']\n",
    "      root = utterances[0]\n",
    "      prev_utt = None\n",
    "      for l in range(len(utterances)):\n",
    "        utterance = utterances[l]\n",
    "        speaker = utterance['speakers']\n",
    "        if len(speaker) == 0:\n",
    "          prev_utt = None\n",
    "          continue\n",
    "        all_utterances[utterance['utterance_id']] = Utterance(\n",
    "            id=utterance['utterance_id'],\n",
    "            user=corpus_users[speaker[0]],\n",
    "            root=root['utterance_id'],\n",
    "            reply_to=prev_utt,\n",
    "            timestamp=None,\n",
    "            text=utterance['transcript']\n",
    "        )\n",
    "        prev_utt = utterance['utterance_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmVQJYBiI1aY",
    "outputId": "70d965af-91c4-4b0d-9fec-477a06b42ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This corpus has 61338/61309 utterances\n"
     ]
    }
   ],
   "source": [
    "print(\"This corpus has {}/61309 utterances\".format(len(all_utterances)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bjb5fkwmN5Ma"
   },
   "source": [
    "# Creating the corpus from a list of utterances\n",
    "\n",
    "We now create the corpus from our dict of utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0C_xjYMfOKVL"
   },
   "outputs": [],
   "source": [
    "utterance_list = [utt for k, utt in all_utterances.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVyGuspKOU7E"
   },
   "outputs": [],
   "source": [
    "friends_corpus = Corpus(utterances=utterance_list, version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oCQcxnu1OZXv",
    "outputId": "37b502a4-f0ff-4cb9-c64d-3679c462344d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of conversations in the dataset=3099\n"
     ]
    }
   ],
   "source": [
    "print(\"number of conversations in the dataset={}\".format(len(friends_corpus.get_conversation_ids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rL-5pRYRcAg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#ALL#',\n",
       " '1st Customer',\n",
       " 'A Casino Boss',\n",
       " 'A Crew Member',\n",
       " 'A Disembodied Voice',\n",
       " 'A Drunken Gambler',\n",
       " 'A Female Student',\n",
       " 'A Male Customer',\n",
       " 'A Student',\n",
       " 'A Tourist',\n",
       " 'A Waiter',\n",
       " 'A Woman',\n",
       " 'Actor',\n",
       " 'Adoption Agency Guy',\n",
       " 'Adrienne',\n",
       " 'Agency Guy',\n",
       " 'Air Hostess',\n",
       " 'Air Stewardess',\n",
       " 'Airline Employee',\n",
       " 'Alan',\n",
       " 'Alex',\n",
       " 'Alexandra Steele',\n",
       " 'Alice Knight',\n",
       " 'Alison',\n",
       " 'Allesandro',\n",
       " \"Amanda (Ross' date)\",\n",
       " 'Amanda Buffamonteezi',\n",
       " 'Amber',\n",
       " 'Amy Green',\n",
       " 'Anchorwoman',\n",
       " 'Andrea',\n",
       " 'Andrea Waltham',\n",
       " 'Angela Delveccio',\n",
       " 'Annabelle',\n",
       " 'Announcement',\n",
       " 'Announcer',\n",
       " 'Another Extra',\n",
       " \"Another Man's Voice\",\n",
       " 'Another Scientist',\n",
       " 'Another Tour Guide',\n",
       " 'Answering Machine',\n",
       " 'Anxious Wedding Guest',\n",
       " 'Arthur',\n",
       " 'Ashley',\n",
       " 'Assistant',\n",
       " 'Attendant',\n",
       " 'Aunt Iris',\n",
       " 'Aunt Lillian',\n",
       " 'Aunt Lisa',\n",
       " 'Aunt Millie',\n",
       " 'Aurora',\n",
       " 'Ballerina',\n",
       " 'Bandleader',\n",
       " 'Bank Officer',\n",
       " 'Barry Farber',\n",
       " 'Bass Singer',\n",
       " 'Ben Geller',\n",
       " 'Benjamin Hobart',\n",
       " 'Bernice',\n",
       " 'Best Man',\n",
       " 'Big Bully',\n",
       " 'Bill',\n",
       " 'Billy',\n",
       " 'Bitsy Hannigan',\n",
       " 'Bitter Lady',\n",
       " 'Bitter Woman',\n",
       " 'Blackjack Dealer',\n",
       " 'Blonde Girl',\n",
       " 'Bob',\n",
       " \"Bob (Chandler's coworker)\",\n",
       " 'Bobby Corso',\n",
       " 'Bobby Rush',\n",
       " 'Bonnie',\n",
       " 'Boss',\n",
       " 'Both',\n",
       " 'Boy',\n",
       " 'Boy In The Cape',\n",
       " 'Brenda',\n",
       " 'Buddy Boyles',\n",
       " 'Buffay',\n",
       " 'Burt',\n",
       " 'C.H.E.E.S.E.',\n",
       " 'Cailin',\n",
       " 'Caitlin',\n",
       " \"Carl (Joey's lookalike)\",\n",
       " \"Carl (Rachel's date)\",\n",
       " 'Carol Willick',\n",
       " 'Caroline',\n",
       " 'Casey',\n",
       " 'Cashier',\n",
       " 'Cassie Geller',\n",
       " 'Casting Assistant',\n",
       " 'Casting Director #1',\n",
       " 'Casting Director #2',\n",
       " 'Casting Director #3',\n",
       " 'Casting Director No. 1',\n",
       " 'Casting Director No. 2',\n",
       " 'Casting Guy',\n",
       " 'Catherine',\n",
       " 'Cecilia',\n",
       " 'Celia',\n",
       " 'Chandler Bing',\n",
       " 'Chandlers',\n",
       " 'Charity Guy',\n",
       " 'Charles Bing',\n",
       " 'Charlie Wheeler',\n",
       " 'Charlton Heston',\n",
       " 'Chase Lassiter',\n",
       " 'Cheryl',\n",
       " 'Chip Matthews',\n",
       " 'Chloe',\n",
       " 'Claudia',\n",
       " 'Clerk',\n",
       " 'Cliff',\n",
       " 'Clown',\n",
       " 'Colleen',\n",
       " 'Coma Guy',\n",
       " 'Commercial',\n",
       " 'Cookie Tribbiani',\n",
       " 'Cop',\n",
       " 'Cowgirl',\n",
       " 'Croupler',\n",
       " 'Customer',\n",
       " 'Customers',\n",
       " 'Cynthia',\n",
       " 'Dan',\n",
       " 'Dana Keystone',\n",
       " 'Danielle',\n",
       " 'Danny',\n",
       " \"Danny's Sister\",\n",
       " 'Dave',\n",
       " 'David',\n",
       " 'Dean Lipson',\n",
       " 'Delivery Girl',\n",
       " 'Delivery Guy',\n",
       " 'Delivery Room Nurse',\n",
       " 'Dennis Phillips',\n",
       " 'Devon',\n",
       " 'Dick Clark',\n",
       " 'Dina',\n",
       " 'Director',\n",
       " \"Director's Assistant\",\n",
       " 'Dirk',\n",
       " 'Doctor',\n",
       " 'Doctor Connelly',\n",
       " 'Don',\n",
       " 'Donny Osmond',\n",
       " 'Doug',\n",
       " 'Dr. Baldhara',\n",
       " 'Dr. Biely',\n",
       " 'Dr. Drake Ramoray',\n",
       " 'Dr. Franzblau',\n",
       " 'Dr. Gettleman',\n",
       " 'Dr. Harad',\n",
       " 'Dr. Horton',\n",
       " 'Dr. Johnson',\n",
       " 'Dr. Ledbetter',\n",
       " 'Dr. Li',\n",
       " 'Dr. Long',\n",
       " 'Dr. Miller',\n",
       " 'Dr. Mitchell',\n",
       " 'Dr. Oberman',\n",
       " 'Dr. Rhodes',\n",
       " 'Dr. Roger',\n",
       " 'Dr. Rosen',\n",
       " 'Dr. Schiff',\n",
       " 'Dr. Stryker Remoray',\n",
       " 'Dr. Wesley',\n",
       " 'Dr. Zane',\n",
       " 'Dressmaker',\n",
       " 'Drew',\n",
       " 'Drunk Man',\n",
       " 'Drunken Gambler',\n",
       " 'Duncan',\n",
       " 'Earl',\n",
       " 'Eddie Menuek',\n",
       " 'Eldad',\n",
       " 'Elizabeth Hornswoggle',\n",
       " 'Elizabeth Stevens',\n",
       " 'Emeril',\n",
       " 'Emil Alexander',\n",
       " 'Emily Waltham',\n",
       " 'Emma',\n",
       " 'Employee',\n",
       " 'Eric',\n",
       " 'Eric (photographer)',\n",
       " 'Erica',\n",
       " 'Erica Ford',\n",
       " 'Erin',\n",
       " 'Ernie',\n",
       " 'Estelle Leonard',\n",
       " 'Ethan',\n",
       " 'Evil Bitch',\n",
       " 'Extra',\n",
       " 'Fake Monica',\n",
       " 'Fat Girl',\n",
       " 'Felicity',\n",
       " 'Female Clerk',\n",
       " 'Female Jeweler',\n",
       " 'Female Student',\n",
       " 'Fergie',\n",
       " 'Fireman',\n",
       " 'Fireman #1',\n",
       " 'Fireman #2',\n",
       " 'Fireman No. 1',\n",
       " 'Fireman No. 2',\n",
       " 'Fireman No. 3',\n",
       " 'First Dorm Guy',\n",
       " 'Flight Attendant',\n",
       " 'Frank Buffay Jr.',\n",
       " 'Frank Buffay Sr.',\n",
       " 'Franny',\n",
       " 'Fredrick',\n",
       " 'Friend',\n",
       " 'Friend No. 1',\n",
       " 'Friend No. 2',\n",
       " 'Front Desk Clerk',\n",
       " 'Gail',\n",
       " 'Gang',\n",
       " 'Gary',\n",
       " 'Gary Collins',\n",
       " \"Gary's Radio\",\n",
       " 'Gate Agent',\n",
       " 'Gate Attendant #1',\n",
       " 'Gate Attendant #2',\n",
       " 'Gavin Mitchell',\n",
       " 'Gene',\n",
       " 'Gerston',\n",
       " 'Gert',\n",
       " 'Ginger',\n",
       " 'Girl',\n",
       " 'Girl 1',\n",
       " 'Girl 1 On Bus',\n",
       " 'Girl 2',\n",
       " 'Girl 2 On Bus',\n",
       " \"Girl's Voice\",\n",
       " 'Glenda',\n",
       " 'Gloria Tribbiani',\n",
       " 'Grandma Tribbiani',\n",
       " 'Grandmother',\n",
       " 'Guest #1',\n",
       " 'Guest #2',\n",
       " 'Guest #3',\n",
       " 'Gunther',\n",
       " 'Guru Saj',\n",
       " 'Guy',\n",
       " 'Guy #1',\n",
       " 'Guy #2',\n",
       " 'Guy All The Way In The Back',\n",
       " 'Guys',\n",
       " 'Gym Employee',\n",
       " 'Handyman',\n",
       " 'Hayley',\n",
       " \"Hayley's Roommate\",\n",
       " 'Health Inspector',\n",
       " 'Heather',\n",
       " 'Helen',\n",
       " 'Helena',\n",
       " 'Henrietta',\n",
       " 'Her Friend',\n",
       " 'Her Friends',\n",
       " 'Hilda',\n",
       " 'Hillary',\n",
       " 'Hitchhiker',\n",
       " 'Hold Voice',\n",
       " 'Hombre Man',\n",
       " 'Hooker',\n",
       " 'Hope',\n",
       " 'Hoshi',\n",
       " 'Host',\n",
       " 'Hotel Clerk',\n",
       " 'Housekeeper',\n",
       " 'Hypnosis Tape',\n",
       " 'Intercom',\n",
       " 'Intern',\n",
       " 'Interviewer',\n",
       " 'Isabella Rosselini',\n",
       " 'Issac',\n",
       " 'Jack',\n",
       " 'Jack Geller',\n",
       " 'Jade',\n",
       " 'Jake',\n",
       " 'Jamie',\n",
       " 'Jane',\n",
       " 'Janice Litman Goralnik',\n",
       " \"Janice's Voice\",\n",
       " 'Janine',\n",
       " 'Janine Lecroix',\n",
       " 'Janitor',\n",
       " 'Jarvis Oberblau',\n",
       " 'Jasmine',\n",
       " 'Jason',\n",
       " 'Jay Leno',\n",
       " 'Jean-Claude Van Damme',\n",
       " 'Jeanette',\n",
       " 'Jeannie',\n",
       " 'Jeannine',\n",
       " 'Jen',\n",
       " 'Jennifer Aniston',\n",
       " 'Jessica Ashley',\n",
       " 'Jessica Lockhart',\n",
       " 'Jester',\n",
       " 'Jill Goodacre',\n",
       " 'Jill Green',\n",
       " 'Jim',\n",
       " 'Jo Lynn',\n",
       " 'Joanna',\n",
       " 'Joanne',\n",
       " 'Joey Tribbiani',\n",
       " 'Joey Tribbiani Sr.',\n",
       " \"Joey's Co-Star\",\n",
       " \"Joey's Date\",\n",
       " \"Joey's Doctor\",\n",
       " \"Joey's Grandmother\",\n",
       " \"Joey's Hand Twin\",\n",
       " \"Joey's Look-A-Like\",\n",
       " \"Joey's Sister\",\n",
       " \"Joey's Sisters\",\n",
       " 'Joshua Burgin',\n",
       " 'Judge',\n",
       " 'Judy Geller',\n",
       " 'Julie',\n",
       " 'Julie Coreger',\n",
       " 'Julie Graff',\n",
       " 'Julio (poet)',\n",
       " 'Kara',\n",
       " 'Karin',\n",
       " 'Kash',\n",
       " 'Kate Miller',\n",
       " 'Kathy',\n",
       " \"Kathy's Co-Star\",\n",
       " 'Katie',\n",
       " 'Katie (saleswoman)',\n",
       " 'Ken',\n",
       " 'Kevin',\n",
       " 'Kid',\n",
       " 'Kids',\n",
       " 'Kiki',\n",
       " 'Kim',\n",
       " 'Kitchen Worker',\n",
       " 'Kori',\n",
       " 'Krista',\n",
       " 'Kristen',\n",
       " 'Kristen Leigh',\n",
       " 'Kristin',\n",
       " 'Kyle',\n",
       " 'Kyle Lowder',\n",
       " 'Lady',\n",
       " 'Larry',\n",
       " 'Laura',\n",
       " 'Lauren',\n",
       " 'Leader',\n",
       " 'Lecturer',\n",
       " 'Lennart',\n",
       " 'Leonard Green',\n",
       " 'Leslie',\n",
       " 'Lewis',\n",
       " 'Liam',\n",
       " 'Lisa',\n",
       " 'Lisa Kudrow',\n",
       " 'Little Bully',\n",
       " 'Little Girl',\n",
       " 'Lizzy',\n",
       " 'Locksmith',\n",
       " 'Lorraine',\n",
       " 'Lowell',\n",
       " 'Lowell (mugger)',\n",
       " 'Luisa Gianetti',\n",
       " 'Lydia',\n",
       " 'Mac',\n",
       " 'Machine',\n",
       " 'Mackenzie',\n",
       " \"Maitre D'\",\n",
       " 'Malcom',\n",
       " 'Male Guest',\n",
       " 'Male Jeweler',\n",
       " 'Male Nurse',\n",
       " 'Male Student',\n",
       " 'Man',\n",
       " 'Man At The Wedding',\n",
       " 'Man On Tv',\n",
       " 'Man With A Bow Tie',\n",
       " \"Man's Voice\",\n",
       " 'Manny',\n",
       " 'Marc Coreger',\n",
       " 'Marge',\n",
       " 'Margha',\n",
       " 'Marjorie',\n",
       " 'Mark Robinson',\n",
       " 'Marsha',\n",
       " 'Mary Ellen',\n",
       " 'Mary-Angela',\n",
       " 'Mary-Theresa',\n",
       " \"Matire'D\",\n",
       " 'Matress King',\n",
       " 'Matthew Ashford',\n",
       " 'Matthew Perry',\n",
       " 'Max',\n",
       " 'Meg',\n",
       " 'Megan Bailey',\n",
       " 'Mel',\n",
       " 'Melanie',\n",
       " 'Melissa Warburton',\n",
       " 'Message',\n",
       " 'Michael',\n",
       " 'Michelle',\n",
       " 'Michelle Burke',\n",
       " 'Mike',\n",
       " 'Mike Hannigan',\n",
       " \"Mike's Dad\",\n",
       " \"Mike's Father\",\n",
       " \"Mike's Mom\",\n",
       " \"Mike's Mother\",\n",
       " 'Mindy Hunter',\n",
       " 'Minister',\n",
       " 'Mischa',\n",
       " 'Missy Goldberg',\n",
       " 'Molly',\n",
       " 'Mona',\n",
       " \"Mona's Date\",\n",
       " 'Monica Geller',\n",
       " \"Monica's Boyfriend\",\n",
       " 'Mover',\n",
       " 'Mr. Adelman',\n",
       " 'Mr. Bowmont',\n",
       " 'Mr. Burgin',\n",
       " 'Mr. Campbell',\n",
       " 'Mr. Douglas',\n",
       " 'Mr. Franklin',\n",
       " 'Mr. Heckles',\n",
       " 'Mr. Kaplan',\n",
       " 'Mr. Posner',\n",
       " 'Mr. Ratstatter',\n",
       " 'Mr. Simon',\n",
       " 'Mr. Thompson',\n",
       " 'Mr. Treeger',\n",
       " 'Mr. Wineburg',\n",
       " 'Mr. Zelner',\n",
       " 'Mrs. Buffay',\n",
       " 'Mrs. Burgin',\n",
       " 'Mrs. Burkart',\n",
       " 'Mrs. Chatracus',\n",
       " 'Mrs. Lynch',\n",
       " 'Mrs. Potter',\n",
       " 'Mrs. Tedlock',\n",
       " \"Mrs. Verhoeven's Daughter\",\n",
       " 'Mrs. Wallace',\n",
       " 'Mrs. Wineburg',\n",
       " 'Ms. Lambert',\n",
       " 'Ms. Mckenna',\n",
       " 'Nancy',\n",
       " 'Narrator',\n",
       " 'Ned Morse',\n",
       " 'Nina Bookbinder',\n",
       " 'Nora Tyler Bing',\n",
       " 'Nurse',\n",
       " 'Nurse #1',\n",
       " 'Nurse #2',\n",
       " 'Nurse Sizemore',\n",
       " 'Old Woman',\n",
       " 'Older Scientist',\n",
       " 'Olivia',\n",
       " 'Others',\n",
       " 'Oven',\n",
       " 'Owen',\n",
       " 'Paleontologist',\n",
       " 'Paolo',\n",
       " 'Parker',\n",
       " 'Party Guests',\n",
       " 'Passenger',\n",
       " 'Passenger #1',\n",
       " 'Passenger #2',\n",
       " 'Passenger #3',\n",
       " 'Passerby',\n",
       " 'Patrick',\n",
       " 'Patron',\n",
       " 'Paul Stevens',\n",
       " 'Paul the Wine Guy',\n",
       " 'Paula',\n",
       " 'Paulo',\n",
       " 'Pbs Volunteer',\n",
       " \"Pete's Mom\",\n",
       " 'Peter',\n",
       " 'Peter Becker',\n",
       " 'Petrie',\n",
       " 'Phil',\n",
       " 'Phoebe Abbott',\n",
       " 'Phoebe Buffay',\n",
       " \"Phoebe's Assistant\",\n",
       " \"Phoebe's Friends\",\n",
       " 'Photographer',\n",
       " 'Pizza Guy',\n",
       " 'Policeman',\n",
       " 'Precious',\n",
       " 'Priest On Tv',\n",
       " 'Producer',\n",
       " 'Producer #1',\n",
       " 'Professor Feesen',\n",
       " 'Professor Sherman',\n",
       " 'Professor Spafford',\n",
       " 'Professore Clerk',\n",
       " 'Prospective Nanny',\n",
       " 'Quartet',\n",
       " 'Racel',\n",
       " 'Rachel Green',\n",
       " \"Rachel's Boss\",\n",
       " 'Radio',\n",
       " 'Ralph Lauren',\n",
       " 'Ray',\n",
       " 'Raymond',\n",
       " 'Realtor',\n",
       " 'Receptionist',\n",
       " 'Referee',\n",
       " 'Richard Burke',\n",
       " \"Richard's Date\",\n",
       " 'Rick Sanoven',\n",
       " 'Rita',\n",
       " 'Rob',\n",
       " 'Robbie',\n",
       " 'Robert Bobby',\n",
       " 'Robin',\n",
       " 'Robin Williams',\n",
       " 'Roger',\n",
       " 'Ronni Rapalono',\n",
       " 'Ross Geller',\n",
       " 'Roy',\n",
       " 'Russ',\n",
       " 'Russell',\n",
       " 'Ryan',\n",
       " 'Salesman',\n",
       " 'Sally',\n",
       " 'Salon Girl',\n",
       " \"Same Man's Voice\",\n",
       " 'Sandra Green',\n",
       " 'Sandy',\n",
       " 'Santos',\n",
       " 'Sarah',\n",
       " 'Sarah Tuttle',\n",
       " 'Scott Alexander',\n",
       " 'Sebastian',\n",
       " 'Second Dorm Guy',\n",
       " 'Second Girl',\n",
       " 'Second Message',\n",
       " 'Secretary',\n",
       " 'Security Guard',\n",
       " 'Sergei',\n",
       " 'Shelley',\n",
       " 'Sherman Whitfield',\n",
       " 'Shop Assistant',\n",
       " 'Sick Bastard',\n",
       " 'Sid Goralnik',\n",
       " 'Singer',\n",
       " 'Sister 1',\n",
       " 'Sleep Clinic Worker',\n",
       " 'Smart Kid',\n",
       " 'Smoke Detector',\n",
       " 'Sonia',\n",
       " 'Soothing Male Voice',\n",
       " 'Sophie',\n",
       " 'Spokeswoman',\n",
       " 'Stage Director',\n",
       " 'Stage Manager',\n",
       " 'Stanley',\n",
       " 'Stephanie',\n",
       " 'Stephanie Schiffer',\n",
       " 'Stephen Waltham',\n",
       " 'Steve',\n",
       " 'Steve (drug addict)',\n",
       " 'Steve Cera',\n",
       " 'Steven Fisher',\n",
       " 'Stevens',\n",
       " 'Store Guy',\n",
       " 'Strange Man',\n",
       " 'Stranger',\n",
       " 'Stripper',\n",
       " 'Stu',\n",
       " 'Student',\n",
       " 'Supervisor',\n",
       " 'Susan Bunch',\n",
       " 'Susie Moss',\n",
       " 'Tag Jones',\n",
       " 'Tall Guy',\n",
       " 'Tape',\n",
       " 'Tattoo Artist',\n",
       " 'Teacher',\n",
       " 'Terry',\n",
       " 'The \"Hey Guy\" Guy',\n",
       " 'The A.D',\n",
       " 'The Acting Teacher',\n",
       " 'The Assistant Director',\n",
       " 'The Attendant',\n",
       " 'The Bass Barber',\n",
       " 'The Casting Director',\n",
       " 'The Chorus Line',\n",
       " 'The Cigarette Guy',\n",
       " 'The Cigarette Smoking Guy',\n",
       " 'The Colonel',\n",
       " 'The Conductor',\n",
       " 'The Cooking Teacher',\n",
       " 'The Croupier',\n",
       " 'The Cute Guy',\n",
       " 'The Director',\n",
       " 'The Doctor',\n",
       " 'The Dry Cleaner',\n",
       " 'The Fan',\n",
       " 'The Fireman',\n",
       " 'The Flight Attendant',\n",
       " 'The Food Critic',\n",
       " 'The Girls',\n",
       " 'The Grip',\n",
       " 'The Guys',\n",
       " 'The Head Librarian',\n",
       " 'The Hot Girl',\n",
       " 'The Housekeeper',\n",
       " 'The Husband',\n",
       " 'The Instructor',\n",
       " 'The Interviewer',\n",
       " 'The Knocker',\n",
       " 'The Librarian',\n",
       " 'The Little Girl',\n",
       " 'The Lurker',\n",
       " 'The Man',\n",
       " 'The Man In The Sportscar',\n",
       " 'The Museum Official',\n",
       " 'The Old Man',\n",
       " 'The Other Woman',\n",
       " 'The Paramedic',\n",
       " 'The Pastor',\n",
       " 'The Photographer',\n",
       " 'The Porsche Owner',\n",
       " 'The Potential Roommate',\n",
       " 'The Presenter',\n",
       " 'The Producer',\n",
       " 'The Professor',\n",
       " 'The Rabbi',\n",
       " 'The Saleslady',\n",
       " 'The Salesman',\n",
       " 'The Saleswoman',\n",
       " 'The Second Guest',\n",
       " 'The Security Guard',\n",
       " 'The Singing Man',\n",
       " 'The Smoking Woman',\n",
       " 'The Stripper',\n",
       " 'The Teacher',\n",
       " 'The Vampire',\n",
       " 'The Vendor',\n",
       " 'The Waiter',\n",
       " 'The Waitress',\n",
       " 'The Wedding Guest',\n",
       " 'The Whole Party',\n",
       " 'The Woman',\n",
       " 'The Woman Dealer',\n",
       " 'The Woman From Poughkeepsie',\n",
       " 'The Writer',\n",
       " 'Theodore',\n",
       " 'Ticket Agent',\n",
       " 'Ticket Counter Attendant',\n",
       " 'Tilly',\n",
       " 'Tim',\n",
       " 'Timothy Burke',\n",
       " 'Together',\n",
       " 'Tom',\n",
       " 'Tommy',\n",
       " 'Tony',\n",
       " 'Tour Guide',\n",
       " 'Trainer',\n",
       " 'Transit Authority Guy',\n",
       " 'Trudie Styler',\n",
       " 'Tv Announcer',\n",
       " 'Tv Doctor',\n",
       " 'Uncle Dan',\n",
       " 'Ursula',\n",
       " 'Ursula Buffay',\n",
       " 'Vince',\n",
       " 'Voice',\n",
       " 'Waiter',\n",
       " 'Waiter #2',\n",
       " 'Waiter In Drag',\n",
       " 'Waiter No. 2',\n",
       " 'Waiters',\n",
       " 'Waitress',\n",
       " 'Wayne',\n",
       " 'Wedding Planner',\n",
       " 'Wendy',\n",
       " 'Whitney',\n",
       " 'Will Colbert',\n",
       " 'Witch',\n",
       " 'Woman',\n",
       " 'Woman At Door',\n",
       " 'Woman At The Wedding',\n",
       " 'Woman Giving Birth',\n",
       " 'Woman No. 1',\n",
       " 'Woman No. 2',\n",
       " 'Woman On Train',\n",
       " 'Woman On Tv',\n",
       " \"Woman's Voice\",\n",
       " 'Writer',\n",
       " 'Zack',\n",
       " 'Zoe'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_corpus.get_usernames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 699\n",
      "Number of Utterances: 61338\n",
      "Number of Conversations: 3099\n"
     ]
    }
   ],
   "source": [
    "friends_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiUf8K6hTNjV"
   },
   "source": [
    "# Create the corpus dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uhbt1xcCTQGl"
   },
   "outputs": [],
   "source": [
    "friends_corpus.dump(\"corpus\", base_path=\"/Users/emilytseng/Cornell-Conversational-Analysis-Toolkit/datasets/friends-corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emilytseng/Cornell-Conversational-Analysis-Toolkit/datasets/friends-corpus'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "convert-et397.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
