import spacy
from spacy.en import English
from spacy.tokens.doc import Doc
import os


def load_vocab(verbose=False):
	if verbose:
		print('loading spacy vocab')
	return English().vocab

def iterate_spacy(path, vocab):
	with open(path + '.bin', 'rb') as spacy_file:
		with open(path + '.txt') as key_file:
			for doc_bytes in Doc.read_bytes(spacy_file):
				try:
					key = next(key_file)
					doc = Doc(vocab).from_bytes(doc_bytes)
					yield key.strip(), doc
				except:
					continue

def get_spacy_dict(path, vocab=None, verbose=5000):
	'''
		gets a dict of (key --> spacy object) from a path (as generated by the spacify function).
		can pass pre-loaded vocabulary to avoid the terrible load time.

		currently this is super-slow anyways, probably because it's reading in the entire dataset.
		in the ideal world, the dataset would be stored in separate chunks, and we could read in parallel.
	'''
	if not vocab:
		vocab = load_vocab(verbose)
	spacy_dict = {}
	iterable_docs = enumerate(iterate_spacy(path,vocab))
	for idx, (key, doc) in iterable_docs:
		if verbose and (idx > 0) and (idx % verbose == 0):
			print('\t%03d' % idx)
		spacy_dict[key] = doc
	return spacy_dict

def spacify(text_iter, outfile_name, spacy_NLP=None, verbose=5000):
	'''
		spacifies, writes a spacy object = file w/ spacy objects + other files w/ keys to said objects
		text_iter: iterates over text to spacify, yielding index and text
		outfile_name: where to write the spacy file. will write outfile_name.bin, outfile_name.txt
		if you don't want to keep loading spacy NLP objects (which takes a while) then can
			pass an existing spacy_NLP.
	'''
	if not spacy_NLP:
		if verbose:
			print('loading spacy NLP')
		spacy_NLP = spacy.load('en')
	spacy_keys = []
	spacy_objs = []
	for idx,(text_idx, text) in enumerate(text_iter):
		if verbose and (idx > 0) and (idx % verbose == 0):
			print('\t%03d' % idx)
		spacy_keys.append(text_idx)
		spacy_objs.append(spacy_NLP(text).to_bytes())
	with open(outfile_name + '.bin','wb') as f:
		[f.write(byte_val) for byte_val in spacy_objs]
	with open(outfile_name + '.txt','w') as f:
		f.write('\n'.join(spacy_keys))
